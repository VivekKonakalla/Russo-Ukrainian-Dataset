{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02dc43f907f3473890aac19a44b5f802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4db5741b08294c65bd04d87ac6cae21d",
              "IPY_MODEL_a65156c41e9e44f89d7997af06fe84e5",
              "IPY_MODEL_848fd8c3ff604460bc9266f6f624e8ca"
            ],
            "layout": "IPY_MODEL_ce184632d1e848ec8738ae5dfdce247e"
          }
        },
        "4db5741b08294c65bd04d87ac6cae21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_633bd3f9286047d3af7a557c66a5766c",
            "placeholder": "​",
            "style": "IPY_MODEL_4396c0d0be584955b4b317bf6e4ab8b9",
            "value": "Pandas Apply: 100%"
          }
        },
        "a65156c41e9e44f89d7997af06fe84e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33809bd2950841ddada22a4ca10112ff",
            "max": 47463,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ce3e2d8e02048b39ffea39d410841b8",
            "value": 47463
          }
        },
        "848fd8c3ff604460bc9266f6f624e8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_689cc3ccdf0d42f1be2ac24f131549ad",
            "placeholder": "​",
            "style": "IPY_MODEL_eb68fb5bc8f14c8b8ca74fa00513e8be",
            "value": " 47463/47463 [00:02&lt;00:00, 21525.91it/s]"
          }
        },
        "ce184632d1e848ec8738ae5dfdce247e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "633bd3f9286047d3af7a557c66a5766c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4396c0d0be584955b4b317bf6e4ab8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33809bd2950841ddada22a4ca10112ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ce3e2d8e02048b39ffea39d410841b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "689cc3ccdf0d42f1be2ac24f131549ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb68fb5bc8f14c8b8ca74fa00513e8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWrpO6jra6U1",
        "outputId": "8f514ad4-4199-41f0-8952-539b6951df9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load text data into a pandas DataFrame\n",
        "data = pd.read_csv('/content/drive/MyDrive/UROP/0819_UkraineCombinedTweetsDeduped.csv')"
      ],
      "metadata": {
        "id": "4IweiujBGBZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Count of columns in the dataset is:  ', len(data.columns))\n",
        "print('Count of rows in the dataset is:  ', len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL-q1-O-F5YU",
        "outputId": "20906976-b3ee-4994-d756-c506bae553ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of columns in the dataset is:   29\n",
            "Count of rows in the dataset is:   47994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mrMlLFHF5R_",
        "outputId": "beff0007-1ff1-468c-f205-00660d75bb86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'userid', 'username', 'acctdesc', 'location', 'following',\n",
              "       'followers', 'totaltweets', 'usercreatedts', 'tweetid',\n",
              "       'tweetcreatedts', 'retweetcount', 'text', 'hashtags', 'language',\n",
              "       'coordinates', 'favorite_count', 'is_retweet', 'original_tweet_id',\n",
              "       'original_tweet_userid', 'original_tweet_username',\n",
              "       'in_reply_to_status_id', 'in_reply_to_user_id',\n",
              "       'in_reply_to_screen_name', 'is_quote_status', 'quoted_status_id',\n",
              "       'quoted_status_userid', 'quoted_status_username', 'extractedts'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[[\"text\"]].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bLc508QMF5PN",
        "outputId": "c21242da-56b2-4b3a-c5da-0880a2751c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  Dear vaccine advocate\\n\\nDo take the COVID19 m...\n",
              "1  #Mundo \\n\\nAl menos 6 muertos y 16 heridos en ...\n",
              "2  Animal shelter Dogs and Cats, we need your hel...\n",
              "3  Welcome to our shelter!\\nLocated in Ukraine, K...\n",
              "4  Tensión, debido a que #Rusia sigue en pie en l..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89e8632f-d30a-4813-b9e9-6fef29ce2499\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dear vaccine advocate\\n\\nDo take the COVID19 m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#Mundo \\n\\nAl menos 6 muertos y 16 heridos en ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Animal shelter Dogs and Cats, we need your hel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Welcome to our shelter!\\nLocated in Ukraine, K...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tensión, debido a que #Rusia sigue en pie en l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89e8632f-d30a-4813-b9e9-6fef29ce2499')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89e8632f-d30a-4813-b9e9-6fef29ce2499 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89e8632f-d30a-4813-b9e9-6fef29ce2499');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load text data into a pandas DataFrame\n",
        "data = pd.read_csv('/content/drive/MyDrive/UROP/0819_UkraineCombinedTweetsDeduped.csv')\n",
        "\n",
        "# Filter out rows that contain unwanted data\n",
        "unwanted_data = ['WTI:', 'Brent:', 'EST', '#putin', '#petroleumengineering', '#bakerhughes']\n",
        "filtered_data = data[~data['text'].str.contains('|'.join(unwanted_data))]\n",
        "\n",
        "# Select only the 'username' and 'text' columns\n",
        "new_data = filtered_data[['username', 'text']]\n",
        "\n",
        "# Rename the 'text' column to 'tweet'\n",
        "new_data.rename(columns={'text': 'tweet'}, inplace=True)\n",
        "\n",
        "# Add an index of serial number to the new data\n",
        "new_data.insert(0, 'serial_no', range(1, 1 + len(new_data)))\n",
        "\n",
        "# Save the new DataFrame to a new CSV file\n",
        "new_data.to_csv('/content/drive/MyDrive/Group_4_UROP/UserNameTweet_stage_1.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrWToQ_Ja9xU",
        "outputId": "98f1b367-6300-417f-c907-dd035cf32a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-98bf7b0cf21b>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_data.rename(columns={'text': 'tweet'}, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load text data into a pandas DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/Group_4_UROP/UserNameTweet_stage_1.csv',\n",
        "                 lineterminator='\\n')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NjTcOQMqbH08",
        "outputId": "00034411-b314-459b-85d2-1b935ff8c4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   serial_no         username  \\\n",
              "0          1   JoeMokolobetsi   \n",
              "1          2  XclusivasPuebla   \n",
              "2          3  ShelterAnimalUA   \n",
              "3          4  DogandCatHelpe1   \n",
              "4          5   ElMananaOnline   \n",
              "\n",
              "                                               tweet  \n",
              "0  Dear vaccine advocate\\n\\nDo take the COVID19 m...  \n",
              "1  #Mundo \\n\\nAl menos 6 muertos y 16 heridos en ...  \n",
              "2  Animal shelter Dogs and Cats, we need your hel...  \n",
              "3  Welcome to our shelter!\\nLocated in Ukraine, K...  \n",
              "4  Tensión, debido a que #Rusia sigue en pie en l...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40f4368e-ceca-4c3f-ab5a-e804b760b1ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>serial_no</th>\n",
              "      <th>username</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>JoeMokolobetsi</td>\n",
              "      <td>Dear vaccine advocate\\n\\nDo take the COVID19 m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>XclusivasPuebla</td>\n",
              "      <td>#Mundo \\n\\nAl menos 6 muertos y 16 heridos en ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>ShelterAnimalUA</td>\n",
              "      <td>Animal shelter Dogs and Cats, we need your hel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>DogandCatHelpe1</td>\n",
              "      <td>Welcome to our shelter!\\nLocated in Ukraine, K...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>ElMananaOnline</td>\n",
              "      <td>Tensión, debido a que #Rusia sigue en pie en l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40f4368e-ceca-4c3f-ab5a-e804b760b1ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40f4368e-ceca-4c3f-ab5a-e804b760b1ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40f4368e-ceca-4c3f-ab5a-e804b760b1ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Count of columns in the dataset is:  ', len(df.columns))\n",
        "print('Count of rows in the dataset is:  ', len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4zamRS1bHn9",
        "outputId": "9f216b9d-123a-454c-9784-8bbbf55c7329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of columns in the dataset is:   3\n",
            "Count of rows in the dataset is:   47463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74t6EL0iIwz6",
        "outputId": "bc8aaa32-c30b-4e3b-ab3a-95f3d43901b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['serial_no', 'username', 'tweet'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"tweet\"]].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v86yYGFQIwuo",
        "outputId": "d65894bb-4b5b-4a14-df89-1d0af2ba0443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet\n",
              "0  Dear vaccine advocate\\n\\nDo take the COVID19 m...\n",
              "1  #Mundo \\n\\nAl menos 6 muertos y 16 heridos en ...\n",
              "2  Animal shelter Dogs and Cats, we need your hel...\n",
              "3  Welcome to our shelter!\\nLocated in Ukraine, K...\n",
              "4  Tensión, debido a que #Rusia sigue en pie en l..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f370f985-42b5-4184-908b-f4038a49ec9a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dear vaccine advocate\\n\\nDo take the COVID19 m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#Mundo \\n\\nAl menos 6 muertos y 16 heridos en ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Animal shelter Dogs and Cats, we need your hel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Welcome to our shelter!\\nLocated in Ukraine, K...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tensión, debido a que #Rusia sigue en pie en l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f370f985-42b5-4184-908b-f4038a49ec9a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f370f985-42b5-4184-908b-f4038a49ec9a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f370f985-42b5-4184-908b-f4038a49ec9a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install swifter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSOvDGDZJQHi",
        "outputId": "452c6b52-c635-4ca5-973e-d41193479fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting swifter\n",
            "  Downloading swifter-1.3.4.tar.gz (830 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m830.9/830.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from swifter) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.10/dist-packages (from swifter) (5.9.5)\n",
            "Requirement already satisfied: dask[dataframe]>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from swifter) (2022.12.1)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from swifter) (4.65.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from swifter) (7.7.1)\n",
            "Requirement already satisfied: cloudpickle>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from swifter) (2.2.1)\n",
            "Requirement already satisfied: parso>0.4.0 in /usr/local/lib/python3.10/dist-packages (from swifter) (0.8.3)\n",
            "Requirement already satisfied: bleach>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from swifter) (6.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bleach>=3.1.1->swifter) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach>=3.1.1->swifter) (0.5.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (8.1.3)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (2023.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (23.1)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (1.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (6.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (1.22.4)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.0.0->swifter) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.0.0->swifter) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.0.0->swifter) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.0.0->swifter) (3.6.4)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.0.0->swifter) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.0.0->swifter) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->swifter) (2022.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (6.3.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (4.8.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=0.3.10->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (6.4.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (3.1.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (21.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (5.3.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (5.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (1.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.16.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.2.6)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (3.3.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (2.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (4.11.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.7.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (2.4.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->swifter) (2.21)\n",
            "Building wheels for collected packages: swifter\n",
            "  Building wheel for swifter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for swifter: filename=swifter-1.3.4-py3-none-any.whl size=16299 sha256=396db71e238867c17739b492ee77ee52e791a167ec388f7e339866164d31e642\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/bd/3e/2d6afc9bc36c9975f8e4215a270bbac6580c4361ebd6bb2323\n",
            "Successfully built swifter\n",
            "Installing collected packages: jedi, swifter\n",
            "Successfully installed jedi-0.18.2 swifter-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN31wEBpJQFX",
        "outputId": "cb6882a5-9254-411a-a27a-61b458c27b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=fba2432652a527ad019fd3b72902259c05943014116ef546cc9047ae7d12d164\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import swifter\n",
        "import string\n",
        "import re\n",
        "from langdetect import detect\n",
        "from langdetect.lang_detect_exception import LangDetectException\n",
        "\n",
        "# Load the data into a pandas dataframe\n",
        "df = pd.read_csv('/content/drive/MyDrive/Group_4_UROP/UserNameTweet_stage_1.csv', lineterminator='\\n')\n",
        "\n",
        "# Define contractions dictionary\n",
        "contractions = {\n",
        "    \"ain't\": \"am not / are not / is not / has not / have not\",\n",
        "    \"aren't\": \"are not / am not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"can't've\": \"cannot have\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"couldn't've\": \"could not have\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hadn't've\": \"had not have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he had / he would\",\n",
        "    \"he'd've\": \"he would have\",\n",
        "    \"he'll\": \"he shall / he will\",\n",
        "    \"he'll've\": \"he shall have / he will have\",\n",
        "    \"he's\": \"he has / he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how has / how is / how does\",\n",
        "    \"I'd\": \"I had / I would\",\n",
        "    \"I'd've\": \"I would have\",\n",
        "    \"I'll\": \"I shall / I will\",\n",
        "    \"I'll've\": \"I shall have / I will have\",\n",
        "    \"I'm\": \"I am\",\n",
        "    \"I've\": \"I have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it had / it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it shall / it will\",\n",
        "    \"it'll've\": \"it shall have / it will have\",\n",
        "    \"it's\": \"it has / it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she had / she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she shall / she will\",\n",
        "    \"she'll've\": \"she shall have / she will have\",\n",
        "    \"she's\": \"she has / she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"who'd\": \"who would\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who're\": \"who are\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "# Create regular expression pattern for finding contractions\n",
        "pattern = re.compile('({})'.format('|'.join(contractions.keys())), flags=re.IGNORECASE|re.DOTALL)\n",
        "\n",
        "# Define a function to remove non-textual data from a string\n",
        "def remove_non_textual(tweet):\n",
        "    if not isinstance(tweet, str):\n",
        "        tweet = str(tweet)\n",
        "    # Remove URLs\n",
        "    tweet = re.sub(r'http\\S+', '', tweet)\n",
        "    tweet = re.sub(r'www\\S+', '', tweet)\n",
        "    # Remove mentions\n",
        "    tweet = re.sub(r'@\\S+', '', tweet)\n",
        "    # Remove hashtags\n",
        "    tweet = re.sub(r'#\\S+', '', tweet)\n",
        "    # Remove special characters and numbers\n",
        "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
        "    tweet = re.sub(r'\\d+', '', tweet)\n",
        "    # Remove numbers\n",
        "    tweet = tweet.translate(str.maketrans('', '', string.digits))\n",
        "    # Remove punctuation\n",
        "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Convert to lowercase\n",
        "    tweet = tweet.lower()\n",
        "    # Remove extra whitespace\n",
        "    tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
        "    return tweet\n",
        "\n",
        "# Define a function to detect English tweets\n",
        "def is_english(tweet):\n",
        "    # Check if text is at least 10 characters long and contains at least 5 alphabetic characters\n",
        "    if len(tweet) >= 10 and sum(c.isalpha() for c in tweet) >= 5:\n",
        "        try:\n",
        "            # Detect language and return True if the tweet is in English\n",
        "            if detect(tweet) == 'en':\n",
        "                return True\n",
        "        except LangDetectException:\n",
        "            pass\n",
        "    return False\n",
        "\n",
        "#Define function to replace contraction with expanded form\n",
        "def replace(match):\n",
        "    return contractions[match.group(0).lower()]\n",
        "\n",
        "# Define a function to expand contractions\n",
        "def expand_contractions(tweet):\n",
        "    # Replace contractions in tweet\n",
        "    expanded_tweet = pattern.sub(replace, tweet)\n",
        "    return expanded_tweet\n",
        "\n",
        "# Define a function to remove non-ASCII characters\n",
        "def remove_non_ascii(tweet):\n",
        "    return re.sub(r'[^\\x00-\\x7f]', r'', tweet)\n",
        "\n",
        "# Apply the cleaning functions in sequence\n",
        "df['tweet'] = df['tweet'].swifter.apply(remove_non_textual)\n",
        "df['tweet'] = df['tweet'].apply(expand_contractions)\n",
        "df['tweet'] = df['tweet'].apply(remove_non_ascii)\n",
        "\n",
        "# Remove rows with empty tweets\n",
        "df = df[df['tweet'] != '']\n",
        "\n",
        "# Drop rows with missing tweet values\n",
        "df.dropna(subset=['tweet'], inplace=True)\n",
        "\n",
        "# Apply the is_english function to filter out non-English tweets\n",
        "df = df[df['tweet'].apply(is_english)]\n",
        "\n",
        "# Reset the index of the \"serial_no\" column to have sequential order starting from 1\n",
        "df['serial_no'] = range(1, len(df) + 1)\n",
        "\n",
        "# Keep only the desired columns\n",
        "df = df[['serial_no', 'username', 'tweet']]\n",
        "\n",
        "# Save the processed data to a new CSV file\n",
        "df.to_csv('/content/drive/MyDrive/Group_4_UROP/Processed_data_stage_2.csv', index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "02dc43f907f3473890aac19a44b5f802",
            "4db5741b08294c65bd04d87ac6cae21d",
            "a65156c41e9e44f89d7997af06fe84e5",
            "848fd8c3ff604460bc9266f6f624e8ca",
            "ce184632d1e848ec8738ae5dfdce247e",
            "633bd3f9286047d3af7a557c66a5766c",
            "4396c0d0be584955b4b317bf6e4ab8b9",
            "33809bd2950841ddada22a4ca10112ff",
            "8ce3e2d8e02048b39ffea39d410841b8",
            "689cc3ccdf0d42f1be2ac24f131549ad",
            "eb68fb5bc8f14c8b8ca74fa00513e8be"
          ]
        },
        "id": "lGrhxtzcIwrm",
        "outputId": "f9a4b79a-df7f-4c18-8bb1-dbddf41f4e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Pandas Apply:   0%|          | 0/47463 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02dc43f907f3473890aac19a44b5f802"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-78f99d484ce8>:165: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(subset=['tweet'], inplace=True)\n",
            "<ipython-input-48-78f99d484ce8>:171: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['serial_no'] = range(1, len(df) + 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Group_4_UROP/LIWC-22 Results - Processed_data_stage_2 - LIWC Analysis.csv')\n",
        "\n",
        "# Define the linguistic features for OCEAN score calculation\n",
        "linguistic_features = [\n",
        "    'Tone', 'WPS', 'BigWords', 'pronoun', 'prep', 'auxverb', 'adverb', 'conj', 'negate', 'verb', 'adj',\n",
        "    'Drives', 'affiliation', 'achieve', 'Cognition', 'cogproc', 'insight', 'cause', 'discrep', 'tentat',\n",
        "    'certitude', 'differ', 'memory', 'Affect', 'tone_pos', 'tone_neg', 'emotion', 'emo_pos', 'emo_neg',\n",
        "    'emo_anx', 'emo_anger', 'emo_sad', 'swear', 'Social', 'socbehav', 'prosocial', 'polite', 'conflict',\n",
        "    'moral', 'comm', 'socrefs', 'family', 'friend', 'female', 'male', 'Culture', 'politic', 'ethnicity',\n",
        "    'tech', 'Lifestyle', 'leisure', 'home', 'work', 'money', 'relig', 'Physical', 'health', 'illness',\n",
        "    'wellness', 'mental', 'substances', 'sexual', 'food', 'death', 'need', 'want', 'acquire', 'lack',\n",
        "    'fulfill', 'fatigue', 'reward', 'risk', 'curiosity', 'allure', 'Perception', 'attention', 'motion',\n",
        "    'space', 'visual', 'auditory', 'feeling', 'time', 'focuspast', 'focuspresent', 'focusfuture',\n",
        "    'Conversation', 'netspeak', 'assent', 'nonflu', 'filler'\n",
        "]\n",
        "\n",
        "# Define the Big Five personality traits and their corresponding linguistic features\n",
        "traits = {\n",
        "    'openness': ['Tone', 'WPS', 'BigWords', 'cogproc', 'insight', 'cause', 'discrep', 'tentat',\n",
        "                 'certitude', 'differ', 'memory'],\n",
        "    'conscientiousness': ['Analytic', 'Clout', 'Tone', 'WPS', 'BigWords', 'cogproc', 'cause',\n",
        "                          'certitude', 'differ', 'work'],\n",
        "    'extraversion': ['Clout', 'Tone', 'WPS', 'BigWords', 'pronoun', 'Social', 'affiliation',\n",
        "                     'achieve', 'cogproc', 'insight', 'cause', 'discrep', 'tentat', 'certitude',\n",
        "                     'differ', 'memory'],\n",
        "    'agreeableness': ['Tone', 'WPS', 'BigWords', 'pronoun', 'Social', 'affiliation', 'cogproc',\n",
        "                      'insight', 'cause', 'discrep', 'tentat', 'certitude', 'differ', 'memory',\n",
        "                      'socbehav', 'prosocial', 'polite', 'conflict', 'comm', 'socrefs',\n",
        "                      'family', 'friend', 'female', 'male'],\n",
        "    'neuroticism': ['Tone', 'WPS', 'BigWords', 'pronoun', 'Affect', 'tone_pos', 'tone_neg',\n",
        "                    'emotion', 'emo_pos', 'emo_neg', 'emo_anx', 'emo_anger', 'emo_sad',\n",
        "                    'death', 'illness', 'mental']\n",
        "}\n",
        "\n",
        "# Calculate OCEAN scores for each individual\n",
        "ocean_scores = pd.DataFrame(columns=['username'] + list(traits.keys()), dtype=int)\n",
        "for i, row in df.iterrows():\n",
        "    scores = {}\n",
        "    for trait, trait_features in traits.items():\n",
        "        trait_score = np.mean(row[trait_features])\n",
        "\n",
        "        mapped_number = ((trait_score * 3) // 25 + trait_score % 5) % 6 + 3\n",
        "        scaled_score = int(mapped_number)\n",
        "\n",
        "        scores[trait] = scaled_score\n",
        "\n",
        "    ocean_scores.loc[i] = [row['username']] + list(scores.values())\n",
        "\n",
        "\n",
        "# Save the OCEAN scores to a new dataset\n",
        "ocean_scores.to_csv('/content/drive/MyDrive/Group_4_UROP/OCEAN_Scores_Using_LIWC_Analysis.csv', index=False)"
      ],
      "metadata": {
        "id": "pBqUyz33dtvi"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/Group_4_UROP/training_dataset.csv')\n",
        "df = pd.read_csv('/content/drive/MyDrive/Group_4_UROP/OCEAN_Scores_Using_LIWC_Analysis.csv')\n",
        "X_train = data[['openness','conscientiousness','extraversion','agreeableness','neuroticism']]\n",
        "y_train=data['Personality']\n",
        "y_test = df[['openness','conscientiousness','extraversion','agreeableness','neuroticism']]\n",
        "clf = SVC(kernel='poly')\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred = clf.predict(y_test)\n",
        "\n",
        "df['personality'] = y_pred\n",
        "df.to_csv('/content/drive/MyDrive/Group_4_UROP/OCEAN_Scores_With_Personality_Traits.csv', index=False)"
      ],
      "metadata": {
        "id": "lEf3dKeDJFbW"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/drive/MyDrive/Group_4_UROP/OCEAN_Scores_With_Personality_Traits.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "features = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
        "target = 'personality'\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.5, random_state=100)\n",
        "\n",
        "# Initialize and train the Support Vector Classifier (SVC)\n",
        "svc_clf = SVC(C=0.005)  # Adjust the C parameter here\n",
        "svc_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "svc_pred = svc_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "svc_accuracy = accuracy_score(y_test, svc_pred)\n",
        "svc_precision = precision_score(y_test, svc_pred, average='weighted')\n",
        "svc_recall = recall_score(y_test, svc_pred, average='weighted')\n",
        "svc_f1 = f1_score(y_test, svc_pred, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Support Vector Classifier (SVC):\")\n",
        "print(\"Accuracy:\", svc_accuracy)\n",
        "print(\"Precision:\", svc_precision)\n",
        "print(\"Recall:\", svc_recall)\n",
        "print(\"F1-score:\", svc_f1)"
      ],
      "metadata": {
        "id": "eGN03K46K1QS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3368cec4-1a14-44b5-ab72-06334cedd024"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Classifier (SVC):\n",
            "Accuracy: 0.8599982154010886\n",
            "Precision: 0.7976813919250675\n",
            "Recall: 0.8599982154010886\n",
            "F1-score: 0.8245770930580905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/drive/MyDrive/Group_4_UROP/OCEAN_Scores_With_Personality_Traits.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "features = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
        "target = 'personality'\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.5, random_state=50)\n",
        "\n",
        "# Initialize and train the Random Forest Classifier with modified parameters\n",
        "rf_clf = RandomForestClassifier(n_estimators=3, max_depth=3, random_state=50)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "rf_precision = precision_score(y_test, rf_pred, average='weighted')\n",
        "rf_recall = recall_score(y_test, rf_pred, average='weighted')\n",
        "rf_f1 = f1_score(y_test, rf_pred, average='weighted')\n",
        "\n",
        "print(\"\\nRandom Forest Classifier:\")\n",
        "print(\"Accuracy:\", rf_accuracy)\n",
        "print(\"Precision:\", rf_precision)\n",
        "print(\"Recall:\", rf_recall)\n",
        "print(\"F1-score:\", rf_f1)\n"
      ],
      "metadata": {
        "id": "PDzm1R8dK1Na",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "46cb8c73-8053-4958-b013-975e311e51e6"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Classifier:\n",
            "Accuracy: 0.8023556705630409\n",
            "Precision: 0.7411248009911064\n",
            "Recall: 0.8023556705630409\n",
            "F1-score: 0.76735956962452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/drive/MyDrive/Group_4_UROP/OCEAN_Scores_With_Personality_Traits.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "features = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
        "target = 'personality'\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.5, random_state=72)\n",
        "\n",
        "# Initialize and train the MLP Classifier with modified parameters\n",
        "mlp_clf = MLPClassifier(hidden_layer_sizes=(10, 10), alpha=0.2, max_iter=10)\n",
        "mlp_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "mlp_pred = mlp_clf.predict(X_test)\n",
        "\n",
        "mlp_accuracy = accuracy_score(y_test, mlp_pred)\n",
        "mlp_precision = precision_score(y_test, mlp_pred, average='weighted')\n",
        "mlp_recall = recall_score(y_test, mlp_pred, average='weighted')\n",
        "mlp_f1 = f1_score(y_test, mlp_pred, average='weighted')\n",
        "\n",
        "print(\"\\nMLP Classifier:\")\n",
        "print(\"Accuracy:\", mlp_accuracy)\n",
        "print(\"Precision:\", mlp_precision)\n",
        "print(\"Recall:\", mlp_recall)\n",
        "print(\"F1-score:\", mlp_f1)"
      ],
      "metadata": {
        "id": "bAisa3-qK1Ly",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "75d03706-2acd-4848-c196-e58d96b91ab9"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP Classifier:\n",
            "Accuracy: 0.8810564825555457\n",
            "Precision: 0.8453993740263046\n",
            "Recall: 0.8810564825555457\n",
            "F1-score: 0.8512236079698261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/drive/MyDrive/Group_4_UROP/OCEAN_Scores_With_Personality_Traits.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "features = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
        "target = 'personality'\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.5, random_state=62)\n",
        "\n",
        "# Define custom priors for each class\n",
        "custom_priors = [0.1, 0.3, 0.2, 0.15, 0.25]\n",
        "\n",
        "# Initialize and train the Naive Bayes Classifier with modified priors\n",
        "nb_clf = GaussianNB(priors=custom_priors)\n",
        "nb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "nb_pred = nb_clf.predict(X_test)\n",
        "\n",
        "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
        "nb_precision = precision_score(y_test, nb_pred, average='weighted')\n",
        "nb_recall = recall_score(y_test, nb_pred, average='weighted')\n",
        "nb_f1 = f1_score(y_test, nb_pred, average='weighted')\n",
        "\n",
        "print(\"\\nNaive Bayes Classifier:\")\n",
        "print(\"Accuracy:\", nb_accuracy)\n",
        "print(\"Precision:\", nb_precision)\n",
        "print(\"Recall:\", nb_recall)\n",
        "print(\"F1-score:\", nb_f1)"
      ],
      "metadata": {
        "id": "vwKxERNwM_CS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2794b8d9-1c24-4d65-ee42-1918ad5f793c"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Naive Bayes Classifier:\n",
            "Accuracy: 0.770589809940216\n",
            "Precision: 0.8673348541225273\n",
            "Recall: 0.770589809940216\n",
            "F1-score: 0.7969629966805309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/drive/MyDrive/Group_4_UROP/OCEAN_Scores_With_Personality_Traits.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "features = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
        "target = 'personality'\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.5, random_state=82)\n",
        "\n",
        "# Encode the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Build and train the LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Dense(100, input_dim=len(features), activation='relu'))\n",
        "lstm_model.add(Dense(num_classes, activation='softmax'))\n",
        "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping callback to monitor validation loss\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the LSTM model\n",
        "history = lstm_model.fit(X_train, to_categorical(y_train_encoded),\n",
        "                         validation_data=(X_test, to_categorical(y_test_encoded)),\n",
        "                         epochs=5, batch_size=60, callbacks=[early_stopping])\n",
        "\n",
        "# Get the evaluation metrics\n",
        "lstm_loss = history.history['loss'][-1]\n",
        "lstm_accuracy = history.history['accuracy'][-1]\n",
        "val_loss = history.history['val_loss'][-1]\n",
        "val_accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(\"\\nLSTM Model:\")\n",
        "print(\"Loss:\", lstm_loss)\n",
        "print(\"Accuracy:\", lstm_accuracy)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_accuracy)"
      ],
      "metadata": {
        "id": "Ui1gVfa0K1I2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "acce8612-93b5-4e37-961a-9d23dff9e507"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "187/187 [==============================] - 1s 3ms/step - loss: 0.6698 - accuracy: 0.7957 - val_loss: 0.4542 - val_accuracy: 0.8644\n",
            "Epoch 2/5\n",
            "187/187 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8881 - val_loss: 0.3663 - val_accuracy: 0.8924\n",
            "Epoch 3/5\n",
            "187/187 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.9018 - val_loss: 0.3327 - val_accuracy: 0.9036\n",
            "Epoch 4/5\n",
            "187/187 [==============================] - 1s 3ms/step - loss: 0.3073 - accuracy: 0.9095 - val_loss: 0.3060 - val_accuracy: 0.9139\n",
            "Epoch 5/5\n",
            "187/187 [==============================] - 1s 3ms/step - loss: 0.2870 - accuracy: 0.9143 - val_loss: 0.2881 - val_accuracy: 0.9200\n",
            "\n",
            "LSTM Model:\n",
            "Loss: 0.2870079278945923\n",
            "Accuracy: 0.9143316149711609\n",
            "Validation Loss: 0.28813108801841736\n",
            "Validation Accuracy: 0.9200499653816223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, GRU, Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/drive/MyDrive/Group_4_UROP/OCEAN_Scores_With_Personality_Traits.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "features = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
        "target = 'personality'\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.5, random_state=72)\n",
        "\n",
        "# Encode the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Build and train the GRU model\n",
        "gru_model = Sequential()\n",
        "gru_model.add(Dense(100, input_dim=len(features), activation='relu'))\n",
        "gru_model.add(Dense(num_classes, activation='softmax'))\n",
        "gru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping callback to monitor validation loss\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n",
        "\n",
        "# Train the GRU model\n",
        "history = gru_model.fit(X_train, to_categorical(y_train_encoded),\n",
        "                        validation_data=(X_test, to_categorical(y_test_encoded)),\n",
        "                        epochs=5, batch_size=50, callbacks=[early_stopping])\n",
        "\n",
        "# Get the evaluation metrics\n",
        "gru_loss = history.history['loss'][-1]\n",
        "gru_accuracy = history.history['accuracy'][-1]\n",
        "val_loss = history.history['val_loss'][-1]\n",
        "val_accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(\"\\nGRU Model:\")\n",
        "print(\"Loss:\", gru_loss)\n",
        "print(\"Accuracy:\", gru_accuracy)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_accuracy)"
      ],
      "metadata": {
        "id": "VJDC5HW_K1F2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b72a0a43-39ac-41f4-a799-bd332b101d6c"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "225/225 [==============================] - 2s 4ms/step - loss: 0.6138 - accuracy: 0.8021 - val_loss: 0.4274 - val_accuracy: 0.8750\n",
            "Epoch 2/5\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.3715 - accuracy: 0.8888 - val_loss: 0.3600 - val_accuracy: 0.8948\n",
            "Epoch 3/5\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.3286 - accuracy: 0.9018 - val_loss: 0.3402 - val_accuracy: 0.8991\n",
            "Epoch 4/5\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.3016 - accuracy: 0.9133 - val_loss: 0.3042 - val_accuracy: 0.9082\n",
            "Epoch 5/5\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.2846 - accuracy: 0.9167 - val_loss: 0.2866 - val_accuracy: 0.9150\n",
            "\n",
            "GRU Model:\n",
            "Loss: 0.2846258878707886\n",
            "Accuracy: 0.9167410135269165\n",
            "Validation Loss: 0.2865751385688782\n",
            "Validation Accuracy: 0.9149638414382935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing"
      ],
      "metadata": {
        "id": "Qe0qQawtM5Fm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b9b9c5e2-1e5c-47fa-a374-5fe8149ae77c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Group_4_UROP/OCEAN_Scores_With_Personality_Traits.csv')\n",
        "X = data[['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']].values.astype(str)\n",
        "y = data['personality'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Convert X to a list of strings\n",
        "X = [' '.join(x) for x in X]\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "X = pad_sequences(X, maxlen=100)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=52)\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, to_categorical(y_test, num_classes=num_classes)), epochs=3, batch_size=25)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = [list(x).index(max(x)) for x in y_pred]\n",
        "y_test = [list(x).index(max(x)) for x in to_categorical(y_test, num_classes=num_classes)]\n",
        "accuracy1 = accuracy_score(y_test, y_pred)\n",
        "accuracy1 = accuracy1 * 100\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy1))"
      ],
      "metadata": {
        "id": "X4U6bbX-M5C3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4e2eeae1-5961-45af-db4e-6017739ee5bd"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "449/449 [==============================] - 25s 49ms/step - loss: 0.6377 - accuracy: 0.7673 - val_loss: 0.2520 - val_accuracy: 0.9109\n",
            "Epoch 2/3\n",
            "449/449 [==============================] - 18s 40ms/step - loss: 0.2650 - accuracy: 0.9150 - val_loss: 0.1519 - val_accuracy: 0.9501\n",
            "Epoch 3/3\n",
            "449/449 [==============================] - 19s 42ms/step - loss: 0.1948 - accuracy: 0.9396 - val_loss: 0.1783 - val_accuracy: 0.9495\n",
            "351/351 [==============================] - 4s 9ms/step\n",
            "Accuracy: 94.95%\n"
          ]
        }
      ]
    }
  ]
}